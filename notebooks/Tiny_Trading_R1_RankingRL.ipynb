{"nbformat": 4, "nbformat_minor": 5, "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3"}}, "cells": [{"cell_type": "markdown", "metadata": {}, "source": "# Tiny Trading-R1 \u2014 Pairwise Ranking RL Variant"}, {"cell_type": "code", "metadata": {"id": "f266737c-0327-4d52-9234-d55f9775c839"}, "execution_count": null, "outputs": [], "source": "\n# Install deps\nimport sys, subprocess, pkgutil\ndef pip_install(pkg): \n    if pkg not in [m.name for m in pkgutil.iter_modules()]:\n        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", pkg])\nfor p in [\"numpy\",\"pandas\",\"torch\",\"scikit-learn\",\"matplotlib\"]:\n    pip_install(p)\n\nimport numpy as np, pandas as pd, torch, torch.nn as nn, torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.preprocessing import StandardScaler\nimport matplotlib.pyplot as plt\nimport random\nSEED=42\nrandom.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\ndevice=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Device:\", device)\n"}, {"cell_type": "code", "metadata": {"id": "ca7c3343-f2fd-4f30-a7fe-f8fe2463b9a3"}, "execution_count": null, "outputs": [], "source": "\ndef simulate_market(num_days=600, tickers=None):\n    if tickers is None:\n        tickers = [\"NVDA\",\"AAPL\",\"AMZN\",\"META\",\"MSFT\",\"SPY\",\"GOOG\",\"TSLA\",\"NFLX\",\"AMD\"]\n    dates = pd.bdate_range(end=pd.Timestamp.today().normalize(), periods=num_days)\n    rows=[]\n    for tic in tickers:\n        q = np.cumsum(np.random.normal(0,0.02,size=num_days))\n        s = np.cumsum(np.random.normal(0,0.03,size=num_days))\n        m = np.cumsum(np.random.normal(0,0.02,size=num_days))\n        i = np.cumsum(np.random.normal(0,0.015,size=num_days))\n        eps = np.random.normal(0,0.01,size=num_days)\n        r = 0.1*q + 0.07*s + 0.08*m + 0.06*i + 0.6*np.concatenate([[0],eps[:-1]]) + eps\n        price = 100*np.exp(np.cumsum(r*0.02))\n        for d in range(num_days):\n            rows.append({\"date\":dates[d],\"ticker\":tic,\"price\":price[d],\n                         \"f_quality\":q[d],\"f_sentiment\":s[d],\"f_momentum\":m[d],\"f_insider\":i[d]})\n    df = pd.DataFrame(rows).sort_values([\"ticker\",\"date\"]).reset_index(drop=True)\n    df[\"ret1\"]=df.groupby(\"ticker\")[\"price\"].pct_change().fillna(0.0)\n    return df\n\ndef make_features_and_labels(df, horizons=(5,21), vol_lookback=60):\n    df=df.copy()\n    df[\"mom10\"]=df.groupby(\"ticker\")[\"price\"].pct_change(10).fillna(0.0)\n    df[\"mom30\"]=df.groupby(\"ticker\")[\"price\"].pct_change(30).fillna(0.0)\n    df[\"vol\"]=(df.groupby(\"ticker\")[\"ret1\"].rolling(vol_lookback).std().reset_index(level=0,drop=True)).fillna(df[\"ret1\"].std())\n    zbars=[]\n    for h in horizons:\n        fwd=df.groupby(\"ticker\")[\"price\"].pct_change(h).shift(-h)\n        z=(fwd/(df[\"vol\"]+1e-8)).rename(f\"z{h}\")\n        df[f\"z{h}\"]=z; zbars.append(z)\n    df[\"zbar\"]=pd.concat(zbars,axis=1).mean(axis=1)\n    def lab(z):\n        if z <= -1.0: return 0\n        if z <= -0.25: return 1\n        if z < 0.25: return 2\n        if z < 1.0: return 3\n        return 4\n    df[\"label\"]=df[\"zbar\"].apply(lab).astype(int)\n    FEATS=[\"f_quality\",\"f_sentiment\",\"f_momentum\",\"f_insider\",\"mom10\",\"mom30\",\"vol\"]\n    X=df[FEATS].copy().fillna(0.0); y=df[\"label\"].values\n    return df, X, y, FEATS\n\ndf = simulate_market()\ndf, X, y, FEATS = make_features_and_labels(df)\nSECTION_NAMES=[\"market\",\"fundamentals\",\"sentiment\",\"technicals\",\"insider\",\"risks\"]\nCLAIMS=[\n    (\"rev_growth_pos\",  lambda r: r[\"f_quality\"]>0),\n    (\"sentiment_pos\",   lambda r: r[\"f_sentiment\"]>0),\n    (\"momentum_pos\",    lambda r: r[\"f_momentum\"]>0),\n    (\"insider_buying\",  lambda r: r[\"f_insider\"]>0),\n    (\"vol_elevated\",    lambda r: r[\"vol\"]>0.02),\n    (\"mom10_pos\",       lambda r: r[\"mom10\"]>0),\n    (\"mom30_pos\",       lambda r: r[\"mom30\"]>0),\n    (\"divergence_risk\", lambda r: (r[\"mom10\"]>0) and (r[\"f_sentiment\"]<0)),\n]\ndef teacher_structure(n): \n    return np.ones((n,len(SECTION_NAMES)),dtype=np.float32)\ndef teacher_claims(df_rows):\n    out=np.zeros((len(df_rows),len(CLAIMS)),dtype=np.float32)\n    for i,r in enumerate(df_rows):\n        for j,(_,fn) in enumerate(CLAIMS):\n            try: out[i,j]=1.0 if fn(r) else 0.0\n            except: out[i,j]=0.0\n    return out\n"}, {"cell_type": "code", "metadata": {"id": "d577fa08-5c82-49c2-9a33-53de369e6163"}, "execution_count": null, "outputs": [], "source": "\nclass MarketToy(Dataset):\n    def __init__(self, X, y, df_rows, scaler=None, keep_index=False):\n        self.rows = df_rows.reset_index(drop=True)\n        self.keep_index = keep_index\n        Xv = X.values.astype(np.float32) if isinstance(X, pd.DataFrame) else X.astype(np.float32)\n        if scaler is None:\n            self.scaler = StandardScaler()\n            Xv = self.scaler.fit_transform(Xv).astype(np.float32)\n        else:\n            self.scaler = scaler\n            Xv = self.scaler.transform(Xv).astype(np.float32)\n        self.X = Xv\n        self.y = y.astype(np.int64)\n        self.t_struct = teacher_structure(len(Xv))\n        raw = df_rows[[\"f_quality\",\"f_sentiment\",\"f_momentum\",\"f_insider\",\"mom10\",\"mom30\",\"vol\"]].to_dict(orient=\"records\")\n        self.t_claims = teacher_claims(raw)\n        self.idx = np.arange(len(self.X))\n    def __len__(self): return len(self.X)\n    def __getitem__(self,i):\n        tup = (self.X[i], self.y[i], self.t_struct[i], self.t_claims[i])\n        if self.keep_index: return tup + (self.idx[i],)\n        return tup\n\nclass TinyPolicy(nn.Module):\n    def __init__(self, in_dim, hidden=64, n_sections=6, n_claims=8, n_labels=5):\n        super().__init__()\n        self.enc = nn.Sequential(nn.Linear(in_dim,hidden), nn.ReLU(), nn.Linear(hidden,hidden), nn.ReLU())\n        self.h_struct = nn.Linear(hidden, n_sections)\n        self.h_claims = nn.Linear(hidden, n_claims)\n        self.h_dec = nn.Linear(hidden, n_labels)\n    def forward(self, x):\n        h = self.enc(x)\n        return self.h_struct(h), self.h_claims(h), self.h_dec(h)\n    def sample(self, x):\n        ls, lc, ld = self.forward(x)\n        ps=torch.sigmoid(ls); pc=torch.sigmoid(lc); pd=F.softmax(ld,dim=-1)\n        s=torch.bernoulli(ps).detach(); c=torch.bernoulli(pc).detach()\n        d=torch.distributions.Categorical(pd).sample().detach()\n        logp_s=(torch.log(ps+1e-8)*s + torch.log(1-ps+1e-8)*(1-s)).sum(1)\n        logp_c=(torch.log(pc+1e-8)*c + torch.log(1-pc+1e-8)*(1-c)).sum(1)\n        logp_d=torch.log(pd.gather(1,d.view(-1,1))+1e-8).squeeze(1)\n        ent = (-pd*torch.log(pd+1e-8)).sum(1) + (-ps*torch.log(ps+1e-8) - (1-ps)*torch.log(1-ps+1e-8)).sum(1) + (-pc*torch.log(pc+1e-8) - (1-pc)*torch.log(1-pc+1e-8)).sum(1)\n        return (s,c,d),(logp_s,logp_c,logp_d), ent\n"}, {"cell_type": "code", "metadata": {"id": "4d1f6bdc-0994-4a23-9e53-fdd5be0eb7da"}, "execution_count": null, "outputs": [], "source": "\nLABELS=[\"SSell\",\"Sell\",\"Hold\",\"Buy\",\"SBuy\"]\nSIGN=torch.tensor([-1,-1,0,1,1],dtype=torch.float32)\n\ndef structure_score(s): return s.mean(dim=1)\ndef claims_truth(c, batch_raw):\n    truth=[]\n    for r in batch_raw:\n        tr=[]\n        for _,fn in CLAIMS:\n            try: tr.append(1.0 if fn(r) else 0.0)\n            except: tr.append(0.0)\n        truth.append(tr)\n    truth=torch.tensor(truth,dtype=torch.float32, device=c.device)\n    coverage=(c>0.5).float().mean(dim=1)\n    included=(c>0.5).float()\n    correct=((included*truth).sum(dim=1) / (included.sum(dim=1)+1e-6))\n    return coverage*correct\ndef decision_score(d, y_true, zbar):\n    d_sign=SIGN[d]; y_sign=SIGN[y_true]\n    both_hold=((d_sign==0)&(y_sign==0)).float()*0.5\n    base=( (torch.sign(d_sign)*torch.sign(y_sign)>0).float() - (torch.sign(d_sign)*torch.sign(y_sign)<0).float()*1.5 ) + both_hold\n    return base * torch.clamp(torch.abs(zbar),0,2.0)/2.0\ndef composite_reward(s,c,d,batch_rows,y_true,zbar,wS=0.2,wC=0.3,wD=0.5):\n    raw=[{k:float(batch_rows[k][i]) for k in [\"f_quality\",\"f_sentiment\",\"f_momentum\",\"f_insider\",\"mom10\",\"mom30\",\"vol\"]} \n         for i in range(len(batch_rows[\"f_quality\"]))]\n    rS=structure_score(s)\n    rC=claims_truth(c, raw)\n    rD=decision_score(d, y_true, zbar)\n    return wS*rS + wC*rC + wD*rD, rS, rC, rD\n\ndef train_sft(model, loader, opt, epochs=2, dec_weight=1.0):\n    bce=nn.BCEWithLogitsLoss(); ce=nn.CrossEntropyLoss()\n    model.train()\n    for ep in range(epochs):\n        total=0.0\n        for batch in loader:\n            if len(batch)==5: xb,yb,ts,tc,_=batch\n            else: xb,yb,ts,tc=batch\n            xb=torch.tensor(xb, dtype=torch.float32, device=device)\n            yb=torch.tensor(yb, dtype=torch.long, device=device)\n            ts=torch.tensor(ts, dtype=torch.float32, device=device)\n            tc=torch.tensor(tc, dtype=torch.float32, device=device)\n            opt.zero_grad()\n            ls,lc,ld=model(xb)\n            loss=bce(ls,ts)+bce(lc,tc)+dec_weight*ce(ld,yb)\n            loss.backward(); opt.step()\n            total += float(loss.item())\n        print(f\"[SFT] epoch {ep+1}/{epochs} loss={total/len(loader):.4f}\")\n"}, {"cell_type": "code", "metadata": {"id": "c79fd1e1-4647-45ed-8153-52a16ce09501"}, "execution_count": null, "outputs": [], "source": "\ndef batch_rows_dict(df_rows, idxs):\n    sub=df_rows.iloc[list(idxs)]\n    d={k: torch.tensor(sub[k].values, dtype=torch.float32, device=device) \n       for k in [\"f_quality\",\"f_sentiment\",\"f_momentum\",\"f_insider\",\"mom10\",\"mom30\",\"vol\",\"zbar\"]}\n    return d\n\ndef train_pairwise_rft(model, rl_loader, df_rows, opt, epochs=2, entropy_coef=0.001, ce_anchor=0.05):\n    ce=nn.CrossEntropyLoss()\n    for g in opt.param_groups: g[\"lr\"]=g[\"lr\"]*0.5\n    model.train()\n    for ep in range(epochs):\n        stats=[]\n        for batch in rl_loader:\n            xb,yb,_,_,idxs=batch\n            xb=torch.tensor(xb, dtype=torch.float32, device=device)\n            yb=torch.tensor(yb, dtype=torch.long, device=device)\n            rows = batch_rows_dict(df_rows, idxs)\n            # candidate 1\n            (s1,c1,d1),(lp_s1,lp_c1,lp_d1), ent1 = model.sample(xb)\n            R1,_,_,_ = composite_reward(s1,c1,d1,rows,yb,rows[\"zbar\"])\n            # candidate 2\n            (s2,c2,d2),(lp_s2,lp_c2,lp_d2), ent2 = model.sample(xb)\n            R2,_,_,_ = composite_reward(s2,c2,d2,rows,yb,rows[\"zbar\"])\n            logp1 = (lp_s1+lp_c1+lp_d1); logp2=(lp_s2+lp_c2+lp_d2)\n            A1 = 0.5*(R1 - R2); A2 = -A1\n            pol_loss = -(A1.detach()*logp1 + A2.detach()*logp2).mean()\n            ent = torch.cat([ent1,ent2],dim=0).mean()\n            _,_,ld = model(xb)\n            anchor = ce(ld, yb)\n            loss = pol_loss - entropy_coef*ent + ce_anchor*anchor\n            opt.zero_grad(); loss.backward(); opt.step()\n            stats.append([R1.mean().item(),R2.mean().item(),A1.abs().mean().item(),ent.item()])\n        s=np.array(stats).mean(axis=0)\n        print(f\"[Rank-RFT] epoch {ep+1}/{epochs} R1={s[0]:.3f} R2={s[1]:.3f} | |A|={s[2]:.3f} | H={s[3]:.3f}\")\n"}, {"cell_type": "code", "metadata": {"id": "74655087-ddb7-46b9-b7d5-5873c85a5457"}, "execution_count": null, "outputs": [], "source": "\ndef sharpe(returns):\n    if len(returns)==0: return 0.0\n    r=np.array(returns); mu=r.mean(); sd=r.std()+1e-9\n    return (mu/sd)*np.sqrt(252)\ndef max_drawdown(equity):\n    eq=np.array(equity); peak=np.maximum.accumulate(eq); dd=(eq-peak)/peak\n    return dd.min() if len(dd) else 0.0\n\ndef run_walk_forward(df, X, y, feats, n_folds=3, train_days=320, test_days=120, batch=256):\n    model=TinyPolicy(len(feats)).to(device)\n    all_equity=[1.0]; all_returns=[]\n    start_idx=0; fold=0\n    while True:\n        fold+=1\n        if start_idx+train_days+test_days >= len(df): break\n        tr_idx=range(start_idx, start_idx+train_days)\n        te_idx=range(start_idx+train_days, start_idx+train_days+test_days)\n        start_idx += test_days\n        if fold>n_folds: break\n        scaler=StandardScaler().fit(X.iloc[tr_idx])\n        tr_ds=MarketToy(X.iloc[tr_idx], y[tr_idx], pd.concat([df.iloc[tr_idx][feats], df.iloc[tr_idx][[\"zbar\"]]], axis=1), scaler=scaler)\n        tr_ds_rl=MarketToy(X.iloc[tr_idx], y[tr_idx], pd.concat([df.iloc[tr_idx][feats], df.iloc[tr_idx][[\"zbar\"]]], axis=1), scaler=scaler, keep_index=True)\n        te_ds=MarketToy(X.iloc[te_idx], y[te_idx], pd.concat([df.iloc[te_idx][feats], df.iloc[te_idx][[\"zbar\"]]], axis=1), scaler=scaler)\n        tr_loader=DataLoader(tr_ds,batch_size=batch,shuffle=True,drop_last=False)\n        rl_loader=DataLoader(tr_ds_rl,batch_size=batch,shuffle=False,drop_last=False)\n        te_loader=DataLoader(te_ds,batch_size=batch,shuffle=False,drop_last=False)\n        opt=torch.optim.Adam(model.parameters(), lr=3e-3)\n        print(f\"\\n=== Fold {fold} ===\")\n        train_sft(model, tr_loader, opt, epochs=2, dec_weight=1.0)\n        df_tr_rows=pd.concat([df.iloc[tr_idx][feats], df.iloc[tr_idx][[\"zbar\"]]], axis=1).reset_index(drop=True)\n        train_pairwise_rft(model, rl_loader, df_tr_rows, opt, epochs=2, entropy_coef=0.001, ce_anchor=0.05)\n        # Test\n        model.eval(); eq=all_equity[-1]\n        equity_curve=[]; daily_rets=[]\n        with torch.no_grad():\n            xb=torch.tensor(te_ds.X, dtype=torch.float32, device=device)\n            _,_,ld=model(xb)\n            pred=ld.argmax(1).cpu().numpy()\n            pos=np.where(pred<=1,-1,np.where(pred>=3,1,0))\n            fwd21=df.iloc[te_idx].groupby(\"ticker\")[\"price\"].pct_change(21).shift(-21).fillna(0.0).values\n            pnl = pos * fwd21; daily = pnl/21.0\n            for r in daily:\n                eq *= (1.0 + r)\n                equity_curve.append(eq); daily_rets.append(r)\n        all_equity += equity_curve; all_returns += daily_rets\n    S=sharpe(all_returns); MDD=max_drawdown(all_equity)\n    return all_equity, S, MDD\n\nequity, S, MDD = run_walk_forward(df, X, y, FEATS)\nprint(f\"Sharpe: {S:.2f} | Max Drawdown: {MDD:.2%}\")\n"}, {"cell_type": "code", "metadata": {"id": "e95ea8a4-774f-4b7a-a25a-61d6ac0c69c5"}, "execution_count": null, "outputs": [], "source": "\nimport matplotlib.pyplot as plt\nplt.figure(figsize=(8,4)); plt.plot(equity); plt.grid(True)\nplt.title(\"Equity Curve \u2014 Pairwise Ranking RL (Toy)\"); plt.xlabel(\"Test Days\"); plt.ylabel(\"Equity\")\nplt.show()\n"}]}
